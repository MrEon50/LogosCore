#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üß† LOGOS-ASM ‚Äî Terminal ≈öwiadomo≈õci Kodu
Semantyczny System Uczenia Kodu Maszynowego z DRM
"""

import os
import sys
import json
import math
import random
import re
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, asdict
from datetime import datetime
import pickle


@dataclass
class Rule:
    """Regu≈Ça poznawcza w Dynamic Rule Matrix"""
    id: int
    pattern: str
    semantic: str
    weight: float = 0.5
    count: int = 0
    activity: float = 0.0
    time_created: int = 0
    correlation: float = 0.5
    last_used: int = 0
    success_rate: float = 0.5
    
    def calculate_strength(self, current_time: int) -> float:
        """Oblicza si≈Çƒô regu≈Çy wed≈Çug wzoru DRM"""
        if self.count == 0:
            return 0.0
        
        time_factor = 1 + (self.activity / max(current_time, 1))
        strength = (self.weight * 
                   math.log(self.count + 1) * 
                   time_factor * 
                   self.correlation)
        return max(0.0, strength)


class InstructionParser:
    """Parser instrukcji assemblera i kodu maszynowego"""
    
    def __init__(self):
        self.asm_patterns = {
            r'MOV\s+(\w+),\s*(\w+)': 'transfer_data',
            r'ADD\s+(\w+),\s*(\w+)': 'arithmetic_add',
            r'SUB\s+(\w+),\s*(\w+)': 'arithmetic_sub',
            r'MUL\s+(\w+),\s*(\w+)': 'arithmetic_mul',
            r'DIV\s+(\w+),\s*(\w+)': 'arithmetic_div',
            r'CMP\s+(\w+),\s*(\w+)': 'compare_values',
            r'JMP\s+(\w+)': 'unconditional_jump',
            r'JE\s+(\w+)': 'jump_if_equal',
            r'JNE\s+(\w+)': 'jump_if_not_equal',
            r'JL\s+(\w+)': 'jump_if_less',
            r'JG\s+(\w+)': 'jump_if_greater',
            r'PUSH\s+(\w+)': 'stack_push',
            r'POP\s+(\w+)': 'stack_pop',
            r'CALL\s+(\w+)': 'function_call',
            r'RET': 'function_return',
            r'NOP': 'no_operation',
            r'INT\s+(\w+)': 'interrupt_call',
            r'LOAD\s+(\w+),\s*(\w+)': 'memory_load',
            r'STORE\s+(\w+),\s*(\w+)': 'memory_store'
        }
        
        self.semantic_meanings = {
            'transfer_data': 'przeniesienie danych miƒôdzy rejestrami/pamiƒôciƒÖ',
            'arithmetic_add': 'operacja dodawania arytmetycznego',
            'arithmetic_sub': 'operacja odejmowania arytmetycznego',
            'arithmetic_mul': 'operacja mno≈ºenia arytmetycznego',
            'arithmetic_div': 'operacja dzielenia arytmetycznego',
            'compare_values': 'por√≥wnanie warto≈õci i ustawienie flag',
            'unconditional_jump': 'bezwarunkowy skok do etykiety',
            'jump_if_equal': 'skok warunkowy je≈õli r√≥wne',
            'jump_if_not_equal': 'skok warunkowy je≈õli r√≥≈ºne',
            'jump_if_less': 'skok warunkowy je≈õli mniejsze',
            'jump_if_greater': 'skok warunkowy je≈õli wiƒôksze',
            'stack_push': 'umieszczenie warto≈õci na stosie',
            'stack_pop': 'pobranie warto≈õci ze stosu',
            'function_call': 'wywo≈Çanie funkcji/procedury',
            'function_return': 'powr√≥t z funkcji',
            'no_operation': 'brak operacji - pauza',
            'interrupt_call': 'wywo≈Çanie przerwania systemowego',
            'memory_load': '≈Çadowanie danych z pamiƒôci',
            'memory_store': 'zapisywanie danych do pamiƒôci'
        }

    def parse_instruction(self, instruction: str) -> Tuple[Optional[str], Optional[str]]:
        """Parsuje instrukcjƒô i zwraca typ oraz semantykƒô"""
        instruction = instruction.strip().upper()
        
        for pattern, instr_type in self.asm_patterns.items():
            if re.match(pattern, instruction):
                semantic = self.semantic_meanings.get(instr_type, 'nieznana operacja')
                return instr_type, semantic
        
        return None, None

    def binary_to_asm(self, binary_str: str) -> str:
        """Symuluje konwersjƒô kodu binarnego na assembler"""
        if not binary_str or len(binary_str) % 8 != 0:
            return "INVALID"
        
        # Uproszczona symulacja - mapowanie wzorc√≥w binarnych
        binary_patterns = {
            '10110000': 'MOV AL, imm8',
            '10001000': 'MOV r/m8, r8',
            '00000100': 'ADD AL, imm8',
            '00101100': 'SUB AL, imm8',
            '00111100': 'CMP AL, imm8',
            '11101001': 'JMP rel32',
            '01010000': 'PUSH EAX',
            '01011000': 'POP EAX',
            '11101000': 'CALL rel32',
            '11000011': 'RET',
            '10010000': 'NOP'
        }
        
        chunks = [binary_str[i:i+8] for i in range(0, len(binary_str), 8)]
        asm_instructions = []
        
        for chunk in chunks:
            asm = binary_patterns.get(chunk, f'DB {chunk}')
            asm_instructions.append(asm)
        
        return '\n'.join(asm_instructions)


class DeepSemanticNeuralNetwork:
    """G≈Çƒôboka sieƒá neuronowa dla analizy semantycznej kodu"""

    def __init__(self, input_size=128, hidden_sizes=[256, 128, 64], output_size=32):
        self.input_size = input_size
        self.hidden_sizes = hidden_sizes
        self.output_size = output_size
        self.learning_rate = 0.001
        self.momentum = 0.9

        # Inicjalizacja wag i bias√≥w
        self.weights = []
        self.biases = []
        self.velocities_w = []
        self.velocities_b = []

        # Warstwy: input -> hidden1 -> hidden2 -> hidden3 -> output
        layer_sizes = [input_size] + hidden_sizes + [output_size]

        for i in range(len(layer_sizes) - 1):
            # Xavier/Glorot initialization
            fan_in, fan_out = layer_sizes[i], layer_sizes[i + 1]
            limit = np.sqrt(6.0 / (fan_in + fan_out))

            w = np.random.uniform(-limit, limit, (layer_sizes[i], layer_sizes[i + 1]))
            b = np.zeros((1, layer_sizes[i + 1]))

            self.weights.append(w)
            self.biases.append(b)

            # Momentum velocities
            self.velocities_w.append(np.zeros_like(w))
            self.velocities_b.append(np.zeros_like(b))

        # Semantic embeddings cache
        self.semantic_cache = {}
        self.instruction_embeddings = {}

        # Training history
        self.loss_history = []
        self.accuracy_history = []

    def sigmoid(self, x):
        """Funkcja aktywacji sigmoid z zabezpieczeniem przed overflow"""
        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))

    def relu(self, x):
        """Funkcja aktywacji ReLU"""
        return np.maximum(0, x)

    def leaky_relu(self, x, alpha=0.01):
        """Leaky ReLU activation"""
        return np.where(x > 0, x, alpha * x)

    def softmax(self, x):
        """Softmax activation dla warstwy wyj≈õciowej"""
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)

    def forward(self, x):
        """Forward pass przez sieƒá"""
        activations = [x]

        for i, (w, b) in enumerate(zip(self.weights, self.biases)):
            z = np.dot(activations[-1], w) + b

            if i < len(self.weights) - 1:  # Hidden layers
                if i == 0:
                    a = self.relu(z)  # Pierwsza warstwa: ReLU
                else:
                    a = self.leaky_relu(z)  # Pozosta≈Çe: Leaky ReLU
            else:  # Output layer
                a = self.sigmoid(z)  # Wyj≈õcie: Sigmoid

            activations.append(a)

        return activations

    def encode_instruction(self, instruction: str, instr_type: str = None) -> np.ndarray:
        """Koduje instrukcjƒô do wektora cech"""
        # Cache dla wydajno≈õci
        cache_key = f"{instruction}_{instr_type}"
        if cache_key in self.instruction_embeddings:
            return self.instruction_embeddings[cache_key]

        # Podstawowe cechy instrukcji
        features = np.zeros(self.input_size)

        # 1. Cechy leksykalne (0-31)
        instruction_upper = instruction.upper()

        # Podstawowe instrukcje
        basic_instructions = ['MOV', 'ADD', 'SUB', 'MUL', 'DIV', 'CMP', 'JMP', 'CALL',
                             'RET', 'PUSH', 'POP', 'NOP', 'INT', 'LOAD', 'STORE']
        for i, instr in enumerate(basic_instructions):
            if instr in instruction_upper:
                features[i] = 1.0

        # 2. Cechy syntaktyczne (32-63)
        # Rejestry
        registers = ['A', 'B', 'C', 'D', 'EAX', 'EBX', 'ECX', 'EDX', 'ESP', 'EBP']
        for i, reg in enumerate(registers):
            if reg in instruction_upper:
                features[32 + i] = 1.0

        # Liczby i adresy
        if re.search(r'\d+', instruction):
            features[42] = 1.0  # Zawiera liczby
        if '[' in instruction and ']' in instruction:
            features[43] = 1.0  # Adresowanie po≈õrednie
        if ',' in instruction:
            features[44] = 1.0  # Wiele operand√≥w

        # 3. Cechy semantyczne (64-95)
        if instr_type:
            semantic_types = ['transfer_data', 'arithmetic_add', 'arithmetic_sub',
                             'arithmetic_mul', 'arithmetic_div', 'compare_values',
                             'unconditional_jump', 'jump_if_equal', 'jump_if_not_equal',
                             'stack_push', 'stack_pop', 'function_call', 'function_return']

            for i, sem_type in enumerate(semantic_types):
                if sem_type in instr_type:
                    features[64 + i] = 1.0

        # 4. Cechy kontekstowe (96-127)
        # D≈Çugo≈õƒá instrukcji
        features[96] = min(len(instruction) / 50.0, 1.0)

        # Z≈Ço≈ºono≈õƒá (liczba token√≥w)
        tokens = instruction.split()
        features[97] = min(len(tokens) / 10.0, 1.0)

        # Hash instrukcji dla unikalno≈õci
        instr_hash = hash(instruction) % 30
        features[98 + instr_hash % 30] = 1.0

        # Cache result
        self.instruction_embeddings[cache_key] = features
        return features

    def train_batch(self, instructions, targets, epochs=1):
        """Trenuje sieƒá na batch'u danych"""
        X = np.array([self.encode_instruction(instr[0], instr[1]) for instr in instructions])
        y = np.array(targets)

        for epoch in range(epochs):
            # Forward pass
            activations = self.forward(X)
            predictions = activations[-1]

            # Compute loss (Mean Squared Error)
            loss = np.mean((predictions - y) ** 2)
            self.loss_history.append(loss)

            # Compute accuracy
            pred_classes = np.argmax(predictions, axis=1)
            true_classes = np.argmax(y, axis=1)
            accuracy = np.mean(pred_classes == true_classes)
            self.accuracy_history.append(accuracy)

            # Backward pass
            self._backward(activations, y)

    def _backward(self, activations, y):
        """Backward pass - backpropagation"""
        m = y.shape[0]  # batch size

        # Compute gradients
        dW = []
        db = []

        # Output layer error
        dA = activations[-1] - y  # derivative of MSE

        for i in reversed(range(len(self.weights))):
            # Gradient of weights and biases
            dW_i = np.dot(activations[i].T, dA) / m
            db_i = np.sum(dA, axis=0, keepdims=True) / m

            dW.insert(0, dW_i)
            db.insert(0, db_i)

            if i > 0:  # Not input layer
                # Gradient of activation
                dZ = np.dot(dA, self.weights[i].T)

                # Apply derivative of activation function
                if i == 1:  # First hidden layer (ReLU)
                    dA = dZ * (activations[i] > 0)
                else:  # Other hidden layers (Leaky ReLU)
                    dA = dZ * np.where(activations[i] > 0, 1, 0.01)

        # Update weights with momentum
        for i in range(len(self.weights)):
            # Momentum update
            self.velocities_w[i] = (self.momentum * self.velocities_w[i] -
                                   self.learning_rate * dW[i])
            self.velocities_b[i] = (self.momentum * self.velocities_b[i] -
                                   self.learning_rate * db[i])

            # Apply updates
            self.weights[i] += self.velocities_w[i]
            self.biases[i] += self.velocities_b[i]

    def predict(self, instruction: str, instr_type: str = None) -> np.ndarray:
        """Predykcja dla pojedynczej instrukcji"""
        x = self.encode_instruction(instruction, instr_type).reshape(1, -1)
        activations = self.forward(x)
        return activations[-1][0]

    def get_semantic_similarity(self, instr1: str, instr2: str,
                               type1: str = None, type2: str = None) -> float:
        """Oblicza podobie≈Ñstwo semantyczne miƒôdzy instrukcjami"""
        emb1 = self.encode_instruction(instr1, type1)
        emb2 = self.encode_instruction(instr2, type2)

        # Cosine similarity
        dot_product = np.dot(emb1, emb2)
        norm1 = np.linalg.norm(emb1)
        norm2 = np.linalg.norm(emb2)

        if norm1 == 0 or norm2 == 0:
            return 0.0

        return dot_product / (norm1 * norm2)

    def analyze_instruction_complexity(self, instruction: str, instr_type: str = None) -> Dict:
        """Analizuje z≈Ço≈ºono≈õƒá instrukcji"""
        embedding = self.encode_instruction(instruction, instr_type)
        prediction = self.predict(instruction, instr_type)

        # Analiza r√≥≈ºnych aspekt√≥w
        lexical_complexity = np.sum(embedding[:32])  # Cechy leksykalne
        syntactic_complexity = np.sum(embedding[32:64])  # Cechy syntaktyczne
        semantic_complexity = np.sum(embedding[64:96])  # Cechy semantyczne
        contextual_complexity = np.sum(embedding[96:])  # Cechy kontekstowe

        # Entropia predykcji (miara niepewno≈õci)
        entropy = -np.sum(prediction * np.log(prediction + 1e-10))

        return {
            'lexical_complexity': float(lexical_complexity),
            'syntactic_complexity': float(syntactic_complexity),
            'semantic_complexity': float(semantic_complexity),
            'contextual_complexity': float(contextual_complexity),
            'prediction_entropy': float(entropy),
            'total_complexity': float(np.sum(embedding)),
            'confidence': float(np.max(prediction))
        }

    def get_network_state(self) -> Dict:
        """Zwraca stan sieci neuronowej"""
        return {
            'total_parameters': sum(w.size for w in self.weights) + sum(b.size for b in self.biases),
            'layer_sizes': [self.input_size] + self.hidden_sizes + [self.output_size],
            'training_samples': len(self.loss_history),
            'current_loss': self.loss_history[-1] if self.loss_history else 0.0,
            'current_accuracy': self.accuracy_history[-1] if self.accuracy_history else 0.0,
            'cache_size': len(self.instruction_embeddings)
        }


class DynamicRuleMatrix:
    """System zarzƒÖdzania regu≈Çami poznawczymi"""

    def __init__(self):
        self.rules: Dict[int, Rule] = {}
        self.rule_counter = 0
        self.current_time = 0
        self.learning_rate = 0.1
        self.decay_factor = 0.95
        
    def add_rule(self, pattern: str, semantic: str, weight: float = 0.5) -> int:
        """Dodaje nowƒÖ regu≈Çƒô do macierzy"""
        self.rule_counter += 1
        rule = Rule(
            id=self.rule_counter,
            pattern=pattern,
            semantic=semantic,
            weight=weight,
            time_created=self.current_time
        )
        self.rules[self.rule_counter] = rule
        return self.rule_counter
    
    def update_rule(self, rule_id: int, success: bool = True, activity_boost: float = 1.0):
        """Aktualizuje regu≈Çƒô na podstawie u≈ºycia"""
        if rule_id not in self.rules:
            return
        
        rule = self.rules[rule_id]
        rule.count += 1
        rule.activity += activity_boost
        rule.last_used = self.current_time
        
        if success:
            rule.success_rate = (rule.success_rate * 0.9) + (1.0 * 0.1)
            rule.correlation = min(1.0, rule.correlation + self.learning_rate)
            rule.weight = min(1.0, rule.weight + self.learning_rate * 0.5)
        else:
            rule.success_rate = (rule.success_rate * 0.9) + (0.0 * 0.1)
            rule.correlation = max(0.0, rule.correlation - self.learning_rate)
            rule.weight = max(0.0, rule.weight - self.learning_rate * 0.3)
    
    def decay_rules(self):
        """Stosuje zanik dla nieu≈ºywanych regu≈Ç"""
        for rule in self.rules.values():
            time_since_use = self.current_time - rule.last_used
            if time_since_use > 10:
                rule.weight *= self.decay_factor
                rule.activity *= self.decay_factor
    
    def get_strongest_rules(self, limit: int = 10) -> List[Rule]:
        """Zwraca najsilniejsze regu≈Çy"""
        rules_with_strength = [
            (rule, rule.calculate_strength(self.current_time))
            for rule in self.rules.values()
        ]
        rules_with_strength.sort(key=lambda x: x[1], reverse=True)
        return [rule for rule, _ in rules_with_strength[:limit]]
    
    def remove_weak_rules(self, threshold: float = 0.1):
        """Usuwa regu≈Çy o niskiej sile"""
        to_remove = []
        for rule_id, rule in self.rules.items():
            if rule.calculate_strength(self.current_time) < threshold:
                to_remove.append(rule_id)
        
        for rule_id in to_remove:
            del self.rules[rule_id]
        
        return len(to_remove)
    
    def tick(self):
        """Aktualizuje czas systemowy"""
        self.current_time += 1
        if self.current_time % 50 == 0:
            self.decay_rules()


class ProcessorSimulator:
    """Symulator procesora dla kodu maszynowego"""
    
    def __init__(self):
        self.registers = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'EAX': 0, 'EBX': 0}
        self.memory = [0] * 1024
        self.stack = []
        self.flags = {'zero': False, 'carry': False, 'negative': False}
        self.program_counter = 0
        self.execution_log = []
    
    def reset(self):
        """Resetuje stan procesora"""
        self.registers = {k: 0 for k in self.registers}
        self.memory = [0] * 1024
        self.stack = []
        self.flags = {'zero': False, 'carry': False, 'negative': False}
        self.program_counter = 0
        self.execution_log = []
    
    def execute_instruction(self, instruction: str) -> bool:
        """Wykonuje pojedynczƒÖ instrukcjƒô"""
        instruction = instruction.strip().upper()
        self.execution_log.append(f"PC:{self.program_counter:04d} | {instruction}")
        
        try:
            # MOV
            if match := re.match(r'MOV\s+(\w+),\s*(\w+)', instruction):
                dest, src = match.groups()
                if src.isdigit():
                    self.registers[dest] = int(src)
                else:
                    self.registers[dest] = self.registers.get(src, 0)
            
            # ADD
            elif match := re.match(r'ADD\s+(\w+),\s*(\w+)', instruction):
                dest, src = match.groups()
                val = int(src) if src.isdigit() else self.registers.get(src, 0)
                result = self.registers[dest] + val
                self.registers[dest] = result & 0xFFFFFFFF
                self.flags['zero'] = (result == 0)
                self.flags['carry'] = (result > 0xFFFFFFFF)
            
            # SUB
            elif match := re.match(r'SUB\s+(\w+),\s*(\w+)', instruction):
                dest, src = match.groups()
                val = int(src) if src.isdigit() else self.registers.get(src, 0)
                result = self.registers[dest] - val
                self.registers[dest] = result & 0xFFFFFFFF
                self.flags['zero'] = (result == 0)
                self.flags['negative'] = (result < 0)
            
            # CMP
            elif match := re.match(r'CMP\s+(\w+),\s*(\w+)', instruction):
                reg1, reg2 = match.groups()
                val1 = self.registers.get(reg1, 0)
                val2 = int(reg2) if reg2.isdigit() else self.registers.get(reg2, 0)
                result = val1 - val2
                self.flags['zero'] = (result == 0)
                self.flags['negative'] = (result < 0)
            
            # PUSH
            elif match := re.match(r'PUSH\s+(\w+)', instruction):
                reg = match.group(1)
                self.stack.append(self.registers.get(reg, 0))
            
            # POP
            elif match := re.match(r'POP\s+(\w+)', instruction):
                reg = match.group(1)
                if self.stack:
                    self.registers[reg] = self.stack.pop()
            
            # NOP
            elif instruction == 'NOP':
                pass  # No operation
            
            else:
                self.execution_log.append(f"  B≈ÅƒÑD: Nieznana instrukcja")
                return False
            
            self.program_counter += 1
            return True
            
        except Exception as e:
            self.execution_log.append(f"  B≈ÅƒÑD WYKONANIA: {e}")
            return False
    
    def get_state(self) -> Dict:
        """Zwraca aktualny stan procesora"""
        return {
            'registers': self.registers.copy(),
            'flags': self.flags.copy(),
            'stack_size': len(self.stack),
            'stack_top': self.stack[-1] if self.stack else None,
            'program_counter': self.program_counter
        }


class LogosASM:
    """G≈Ç√≥wny system LOGOS-ASM z Deep Semantic Neural Network"""

    def __init__(self):
        self.drm = DynamicRuleMatrix()
        self.parser = InstructionParser()
        self.processor = ProcessorSimulator()
        self.dsnn = DeepSemanticNeuralNetwork()  # üß† Nowa sieƒá neuronowa

        self.training_data = []
        self.neural_training_data = []  # Dane dla sieci neuronowej
        self.session_stats = {
            'instructions_processed': 0,
            'rules_created': 0,
            'successful_predictions': 0,
            'failed_predictions': 0,
            'neural_predictions': 0,
            'hybrid_predictions': 0
        }
        self.initialize_basic_rules()
        self.training_history = []
        self.metrics_log = []
        self.learning_curves = {
            'accuracy': [],
            'rule_strength': [],
            'prediction_confidence': [],
            'neural_loss': [],
            'neural_accuracy': [],
            'hybrid_performance': []
        }

        # Hybrid prediction system
        self.hybrid_mode = True
        self.neural_weight = 0.3  # Waga sieci neuronowej w predykcji hybrydowej
        self.drm_weight = 0.7     # Waga DRM w predykcji hybrydowej
    
    def initialize_basic_rules(self):
        """Inicjalizuje podstawowe regu≈Çy"""
        basic_rules = [
            ('MOV', 'transfer danych miƒôdzy lokalizacjami', 0.8),
            ('ADD', 'operacja arytmetyczna dodawania', 0.7),
            ('SUB', 'operacja arytmetyczna odejmowania', 0.7),
            ('CMP', 'por√≥wnanie warto≈õci z ustawieniem flag', 0.75),
            ('JMP', 'bezwarunkowy skok w kodzie', 0.6),
            ('PUSH', 'umieszczenie na stosie', 0.65),
            ('POP', 'pobranie ze stosu', 0.65),
            ('CALL', 'wywo≈Çanie procedury', 0.8),
            ('RET', 'powr√≥t z procedury', 0.8)
        ]
        
        for pattern, semantic, weight in basic_rules:
            self.drm.add_rule(pattern, semantic, weight)
    
    def train_on_code(self, code: str, code_type: str = 'asm'):
        """Trenuje system na podanym kodzie - Z DEBUGIEM"""
        lines = code.strip().split('\n')
        
        print(f"\nüîÑ ROZPOCZYNAM TRENING ({code_type}):")
        
        for i, line in enumerate(lines, 1):
            line = line.strip()
            if not line or line.startswith(';') or line.startswith('#'):
                continue
            
            print(f"\nüìù Linia {i}: {line}")
            
            if code_type == 'binary':
                asm_line = self.parser.binary_to_asm(line)
                if asm_line != "INVALID":
                    self._process_instruction(asm_line)
            else:
                self._process_instruction(line)
            
            self.session_stats['instructions_processed'] += 1
        
        self.drm.tick()
        
        print(f"\n‚úÖ TRENING ZAKO≈ÉCZONY:")
        print(f"üìä Utworzono {len(self.drm.rules)} regu≈Ç")
        self.debug_rules()  # Poka≈º wszystkie regu≈Çy
    
    def _process_instruction(self, instruction: str):
        """Przetwarza pojedynczƒÖ instrukcjƒô - HYBRYDOWA WERSJA z DSNN"""
        instr_type, semantic = self.parser.parse_instruction(instruction)

        # üß† NEURAL NETWORK PREDICTION
        neural_prediction = None
        neural_confidence = 0.0

        if self.hybrid_mode:
            try:
                neural_output = self.dsnn.predict(instruction, instr_type)
                neural_confidence = float(np.max(neural_output))
                neural_prediction = self._interpret_neural_output(neural_output)
                self.session_stats['neural_predictions'] += 1
            except Exception as e:
                print(f"  ‚ö†Ô∏è Neural prediction failed: {e}")

        # üßÆ DRM PROCESSING (original logic)
        if instr_type and semantic:
            rule_found = False
            drm_confidence = 0.0

            for rule in self.drm.rules.values():
                if (instr_type.lower() in rule.pattern.lower() or
                    rule.pattern.lower() in instr_type.lower()):
                    self.drm.update_rule(rule.id, True, 1.0)
                    rule_found = True
                    drm_confidence = rule.calculate_strength(self.drm.current_time)
                    print(f"  üîÑ Zaktualizowano regu≈Çƒô #{rule.id}: {rule.pattern}")
                    break

            if not rule_found:
                rule_id = self.drm.add_rule(instr_type, semantic, 0.6)
                self.drm.update_rule(rule_id, True, 1.0)
                self.session_stats['rules_created'] += 1
                drm_confidence = 0.6
                print(f"  ‚ú® Utworzono nowƒÖ regu≈Çƒô #{rule_id}: {instr_type}")

            # ü§ù HYBRID PREDICTION FUSION
            if self.hybrid_mode and neural_prediction:
                hybrid_confidence = (self.drm_weight * drm_confidence +
                                   self.neural_weight * neural_confidence)

                print(f"  ü§ñ Neural: {neural_prediction} (conf: {neural_confidence:.2f})")
                print(f"  üßÆ DRM: {instr_type} (conf: {drm_confidence:.2f})")
                print(f"  ü§ù Hybrid confidence: {hybrid_confidence:.2f}")

                self.session_stats['hybrid_predictions'] += 1

                # Adaptacyjne dostrajanie wag
                if neural_confidence > drm_confidence:
                    self.neural_weight = min(0.5, self.neural_weight + 0.01)
                    self.drm_weight = 1.0 - self.neural_weight
                elif drm_confidence > neural_confidence:
                    self.drm_weight = min(0.8, self.drm_weight + 0.01)
                    self.neural_weight = 1.0 - self.drm_weight

            self.session_stats['successful_predictions'] += 1
        else:
            self.session_stats['failed_predictions'] += 1
            print(f"  ‚ùå Nie rozpoznano instrukcji: {instruction}")

        # Zapisz do danych treningowych (oba systemy)
        self.training_data.append({
            'instruction': instruction,
            'type': instr_type,
            'semantic': semantic,
            'timestamp': self.drm.current_time,
            'neural_prediction': neural_prediction,
            'neural_confidence': neural_confidence
        })

        # Przygotuj dane dla treningu sieci neuronowej
        if instr_type and semantic:
            self.neural_training_data.append({
                'instruction': (instruction, instr_type),
                'target': self._create_neural_target(instr_type, semantic)
            })

    def _interpret_neural_output(self, output: np.ndarray) -> str:
        """Interpretuje wyj≈õcie sieci neuronowej"""
        # Mapowanie indeks√≥w na typy instrukcji
        output_mapping = [
            'transfer_data', 'arithmetic_add', 'arithmetic_sub', 'arithmetic_mul',
            'arithmetic_div', 'compare_values', 'unconditional_jump', 'jump_if_equal',
            'jump_if_not_equal', 'stack_push', 'stack_pop', 'function_call',
            'function_return', 'memory_load', 'memory_store', 'no_operation'
        ]

        if len(output) >= len(output_mapping):
            max_idx = np.argmax(output[:len(output_mapping)])
            return output_mapping[max_idx]
        else:
            return "unknown_neural_output"

    def _create_neural_target(self, instr_type: str, semantic: str) -> np.ndarray:
        """Tworzy target vector dla treningu sieci neuronowej"""
        target = np.zeros(32)  # Output size sieci

        # Mapowanie typ√≥w na indeksy
        type_mapping = {
            'transfer_data': 0, 'arithmetic_add': 1, 'arithmetic_sub': 2,
            'arithmetic_mul': 3, 'arithmetic_div': 4, 'compare_values': 5,
            'unconditional_jump': 6, 'jump_if_equal': 7, 'jump_if_not_equal': 8,
            'stack_push': 9, 'stack_pop': 10, 'function_call': 11,
            'function_return': 12, 'memory_load': 13, 'memory_store': 14,
            'no_operation': 15
        }

        if instr_type in type_mapping:
            target[type_mapping[instr_type]] = 1.0

        # Dodaj informacje semantyczne do pozosta≈Çych wymiar√≥w
        semantic_hash = hash(semantic) % 16
        target[16 + semantic_hash] = 0.5

        return target
    
    def simulate_processor(self, code: str):
        """Symuluje wykonanie kodu na procesorze"""
        self.processor.reset()
        lines = [line.strip() for line in code.split('\n') if line.strip()]
        
        print("\n" + "="*60)
        print("üñ•Ô∏è  SYMULACJA PROCESORA")
        print("="*60)
        
        for line in lines:
            if line and not line.startswith(';'):
                success = self.processor.execute_instruction(line)
                if not success:
                    break
        
        # Poka≈º stan ko≈Ñcowy
        state = self.processor.get_state()
        print(f"\nüìä STAN KO≈ÉCOWY PROCESORA:")
        print(f"Rejestry: {state['registers']}")
        print(f"Flagi: {state['flags']}")
        print(f"Stos: {state['stack_size']} element√≥w")
        print(f"Program Counter: {state['program_counter']}")
        
        return self.processor.execution_log
    
    def introspect_code(self, code: str):
        """Introspekcja kodu z analizƒÖ semantycznƒÖ - NAPRAWIONA"""
        print("\n" + "="*60)
        print("üß† INTROSPEKCJA KODU - ANALIZA SEMANTYCZNA")
        print("="*60)
        
        lines = code.strip().split('\n')
        analysis = []
        
        for i, line in enumerate(lines, 1):
            line = line.strip()
            if not line or line.startswith(';'):
                continue
            
            instr_type, semantic = self.parser.parse_instruction(line)
            
            # NAPRAWKA: Lepsze dopasowywanie regu≈Ç
            matching_rule = None
            max_strength = 0
            
            for rule in self.drm.rules.values():
                # Sprawd≈∫ czy typ instrukcji pasuje do wzorca regu≈Çy
                if instr_type and (
                    instr_type.lower() in rule.pattern.lower() or 
                    rule.pattern.lower() in instr_type.lower() or
                    self._patterns_match(instr_type, rule.pattern)
                ):
                    strength = rule.calculate_strength(self.drm.current_time)
                    if strength > max_strength:
                        max_strength = strength
                        matching_rule = rule
            
            analysis_entry = {
                'line_num': i,
                'instruction': line,
                'type': instr_type or 'UNKNOWN',
                'semantic': semantic or 'nieznane znaczenie',
                'rule': matching_rule,
                'confidence': max_strength
            }
            analysis.append(analysis_entry)
        
        # Wy≈õwietl analizƒô z POPRAWNYMI regu≈Çami
        for entry in analysis:
            print(f"\nLinia {entry['line_num']:2d}: {entry['instruction']}")
            print(f"  Typ: {entry['type']}")
            print(f"  Semantyka: {entry['semantic']}")
            if entry['rule']:
                print(f"  ‚úÖ Regu≈Ça #{entry['rule'].id}: {entry['rule'].pattern}")
                print(f"     Si≈Ça: {entry['confidence']:.2f}")
                print(f"     U≈ºycia: {entry['rule'].count}, Sukces: {entry['rule'].success_rate:.2f}")
            else:
                print(f"  ‚ùå Brak pasujƒÖcej regu≈Çy")
        
        return analysis

    def _patterns_match(self, instr_type, rule_pattern):
        """Sprawdza czy wzorce siƒô dopasowujƒÖ"""
        # Mapowanie typ√≥w instrukcji na wzorce regu≈Ç
        type_to_pattern = {
            'transfer_data': ['MOV', 'LOAD', 'STORE'],
            'arithmetic_add': ['ADD'],
            'arithmetic_sub': ['SUB'],
            'compare_values': ['CMP'],
            'jump_if_equal': ['JE'],
            'stack_push': ['PUSH'],
            'stack_pop': ['POP'],
            'no_operation': ['NOP']
        }
        
        patterns = type_to_pattern.get(instr_type, [])
        return any(pattern.lower() in rule_pattern.lower() for pattern in patterns)
    
    def show_drm_status(self):
        """Wy≈õwietla status Dynamic Rule Matrix"""
        print("\n" + "="*60)
        print("üßÆ DYNAMIC RULE MATRIX - STATUS")
        print("="*60)
        
        strongest_rules = self.drm.get_strongest_rules(10)
        
        if not strongest_rules:
            print("Brak regu≈Ç w macierzy.")
            return
        
        for i, rule in enumerate(strongest_rules, 1):
            strength = rule.calculate_strength(self.drm.current_time)
            print(f"\nRegu≈Ça #{rule.id:02d}: {rule.pattern} ‚Üí \"{rule.semantic}\"")
            print(f"  Waga (W_i):      {rule.weight:.2f}")
            print(f"  WystƒÖpienia (C): {rule.count}")
            print(f"  Aktywno≈õƒá (U):   {rule.activity:.2f}")
            print(f"  Czas (T):        {self.drm.current_time} iteracji")
            print(f"  Korelacja (R):   {rule.correlation:.2f}")
            print(f"  Sukces:          {rule.success_rate:.2f}")
            print(f"  ‚Üí Si = {rule.weight:.2f} * log({rule.count + 1}) * "
                  f"(1 + {rule.activity:.2f}/{self.drm.current_time}) * "
                  f"{rule.correlation:.2f} ‚âà {strength:.2f}")
        
        print(f"\nCa≈Çkowita liczba regu≈Ç: {len(self.drm.rules)}")
        print(f"Aktualny czas systemu: {self.drm.current_time}")
    
    def drm_menu(self):
        """Menu zarzƒÖdzania DRM"""
        while True:
            print("\n" + "‚îÄ"*40)
            print("üßÆ DYNAMIC RULE MATRIX - OPCJE")
            print("‚îÄ"*40)
            print("[a] Dodaj nowƒÖ regu≈Çƒô")
            print("[m] Modyfikuj regu≈Çƒô")
            print("[x] Usu≈Ñ s≈Çabe regu≈Çy")
            print("[r] Raport zmian DRM")
            print("[s] Poka≈º status DRM")
            print("[q] Wr√≥ƒá do menu g≈Ç√≥wnego")
            
            choice = input("\nWybierz opcjƒô: ").lower().strip()
            
            if choice == 'a':
                pattern = input("Wzorzec regu≈Çy: ")
                semantic = input("Znaczenie semantyczne: ")
                try:
                    weight = float(input("Waga poczƒÖtkowa (0.0-1.0): ") or "0.5")
                    rule_id = self.drm.add_rule(pattern, semantic, weight)
                    print(f"‚úÖ Dodano regu≈Çƒô #{rule_id}")
                except ValueError:
                    print("‚ùå B≈Çƒôdna waga")
            
            elif choice == 'm':
                try:
                    rule_id = int(input("ID regu≈Çy do modyfikacji: "))
                    if rule_id in self.drm.rules:
                        rule = self.drm.rules[rule_id]
                        print(f"Aktualna regu≈Ça: {rule.pattern} ‚Üí {rule.semantic}")
                        print(f"Aktualna waga: {rule.weight}")
                        
                        new_weight = input("Nowa waga (Enter = bez zmiany): ")
                        if new_weight:
                            rule.weight = max(0.0, min(1.0, float(new_weight)))
                        
                        new_semantic = input("Nowe znaczenie (Enter = bez zmiany): ")
                        if new_semantic:
                            rule.semantic = new_semantic
                        
                        print("‚úÖ Regu≈Ça zaktualizowana")
                    else:
                        print("‚ùå Nie znaleziono regu≈Çy")
                except ValueError:
                    print("‚ùå B≈Çƒôdne ID")
            
            elif choice == 'x':
                removed = self.drm.remove_weak_rules(0.1)
                print(f"‚úÖ Usuniƒôto {removed} s≈Çabych regu≈Ç")
            
            elif choice == 'r':
                print(f"\nüìä RAPORT DRM:")
                print(f"Ca≈Çkowita liczba regu≈Ç: {len(self.drm.rules)}")
                print(f"Czas systemu: {self.drm.current_time}")
                print(f"Wsp√≥≈Çczynnik uczenia: {self.drm.learning_rate}")
                print(f"Wsp√≥≈Çczynnik zaniku: {self.drm.decay_factor}")
            
            elif choice == 's':
                self.show_drm_status()
            
            elif choice == 'q':
                break
    
    def semantic_experiments(self):
        """Eksperymenty semantyczne"""
        print("\n" + "="*60)
        print("üî¨ EKSPERYMENTY SEMANTYCZNE")
        print("="*60)
        
        experiments = [
            {
                'name': 'Analiza wzorc√≥w transferu danych',
                'code': 'MOV A, B\nMOV C, 100\nMOV D, A\nADD A, C',
                'focus': 'transfer_data'
            },
            {
                'name': 'Analiza operacji arytmetycznych',
                'code': 'ADD A, B\nSUB C, D\nMUL A, 5\nDIV C, 2',
                'focus': 'arithmetic'
            },
            {
                'name': 'Analiza kontroli przep≈Çywu',
                'code': 'CMP A, B\nJE label1\nJMP label2\nCALL func',
                'focus': 'control_flow'
            }
        ]
        
        for exp in experiments:
            print(f"\nüß™ {exp['name']}")
            print("‚îÄ" * 40)
            print(f"Kod testowy:\n{exp['code']}")
            
            # Analizuj kod
            analysis = self.introspect_code(exp['code'])
            
            # Podsumowanie
            types_found = set(entry['type'] for entry in analysis)
            confidence_avg = sum(entry['confidence'] for entry in analysis) / len(analysis)
            
            print(f"\nüìà Podsumowanie eksperymentu:")
            print(f"Wykryte typy instrukcji: {', '.join(types_found)}")
            print(f"≈örednia pewno≈õƒá rozpoznania: {confidence_avg:.2f}")
            
            input("\nNaci≈õnij Enter aby kontynuowaƒá...")
    
    def export_training_data(self):
        """Eksportuje dane treningowe"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Eksport danych treningowych
        training_file = f"logos_training_{timestamp}.json"
        with open(training_file, 'w', encoding='utf-8') as f:
            json.dump(self.training_data, f, ensure_ascii=False, indent=2)
        
        # Eksport regu≈Ç DRM
        rules_data = {
            rule_id: asdict(rule) for rule_id, rule in self.drm.rules.items()
        }
        rules_file = f"logos_rules_{timestamp}.json"
        with open(rules_file, 'w', encoding='utf-8') as f:
            json.dump(rules_data, f, ensure_ascii=False, indent=2)
        
        # Eksport statystyk
        stats_file = f"logos_stats_{timestamp}.json"
        stats = {
            **self.session_stats,
            'drm_rules_count': len(self.drm.rules),
            'drm_time': self.drm.current_time,
            'export_timestamp': timestamp
        }
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        print(f"\n‚úÖ Wyeksportowano dane:")
        print(f"  üìÑ Dane treningowe: {training_file}")
        print(f"  üßÆ Regu≈Çy DRM: {rules_file}")
        print(f"  üìä Statystyki: {stats_file}")
    
    def show_training_dashboard(self):
        """Dashboard treningu w czasie rzeczywistym - HYBRYDOWY"""
        print("\n" + "="*80)
        print("üìä DASHBOARD TRENINGU LOGOS-ASM + DSNN")
        print("="*80)

        # Statystyki DRM
        total_rules = len(self.drm.rules)
        avg_strength = sum(rule.calculate_strength(self.drm.current_time)
                          for rule in self.drm.rules.values()) / max(total_rules, 1)

        print(f"üßÆ DYNAMIC RULE MATRIX:")
        print(f"  Ca≈Çkowita liczba regu≈Ç: {total_rules}")
        print(f"  ≈örednia si≈Ça: {avg_strength:.2f}")
        print(f"  Czas systemu: {self.drm.current_time}")

        # Statystyki sieci neuronowej
        neural_state = self.dsnn.get_network_state()
        print(f"\nüß† DEEP SEMANTIC NEURAL NETWORK:")
        print(f"  Parametry: {neural_state['total_parameters']:,}")
        print(f"  Pr√≥bki treningowe: {neural_state['training_samples']}")
        if neural_state['current_loss'] > 0:
            print(f"  Aktualny loss: {neural_state['current_loss']:.4f}")
            print(f"  Dok≈Çadno≈õƒá: {neural_state['current_accuracy']:.2%}")

        # Tryb hybrydowy
        print(f"\nü§ù TRYB HYBRYDOWY:")
        print(f"  Status: {'‚úÖ W≈ÇƒÖczony' if self.hybrid_mode else '‚ùå Wy≈ÇƒÖczony'}")
        if self.hybrid_mode:
            print(f"  Waga Neural: {self.neural_weight:.2f} | Waga DRM: {self.drm_weight:.2f}")

        # Top 5 najsilniejszych regu≈Ç
        strongest = self.drm.get_strongest_rules(5)
        print(f"\nüèÜ TOP 5 NAJSILNIEJSZYCH REGU≈Å DRM:")
        for i, rule in enumerate(strongest, 1):
            strength = rule.calculate_strength(self.drm.current_time)
            print(f"  {i}. {rule.pattern} ‚Üí {rule.semantic[:30]}...")
            print(f"     Si≈Ça: {strength:.2f} | U≈ºycia: {rule.count} | Sukces: {rule.success_rate:.2f}")

        # Wykres ASCII si≈Çy regu≈Ç
        print(f"\nüìà WYKRES SI≈ÅY REGU≈Å DRM:")
        self._draw_ascii_chart([rule.calculate_strength(self.drm.current_time)
                               for rule in strongest])

        # Statystyki sesji
        print(f"\nüìã STATYSTYKI SESJI:")
        for key, value in self.session_stats.items():
            display_key = key.replace('_', ' ').title()
            print(f"  {display_key}: {value}")

        # Accuracy rates
        total_predictions = (self.session_stats['successful_predictions'] +
                            self.session_stats['failed_predictions'])
        if total_predictions > 0:
            accuracy = self.session_stats['successful_predictions'] / total_predictions * 100
            print(f"\nüìä WYDAJNO≈öƒÜ SYSTEMU:")
            print(f"  Og√≥lna dok≈Çadno≈õƒá: {accuracy:.1f}%")
            self._draw_progress_bar(accuracy, "Dok≈Çadno≈õƒá")

            # Hybrid performance
            if self.session_stats['hybrid_predictions'] > 0:
                hybrid_ratio = self.session_stats['hybrid_predictions'] / total_predictions * 100
                print(f"  Predykcje hybrydowe: {hybrid_ratio:.1f}%")
                self._draw_progress_bar(hybrid_ratio, "Tryb hybrydowy")

        # Neural network learning curves (je≈õli dostƒôpne)
        if len(self.dsnn.loss_history) > 0:
            print(f"\nüß† KRZYWA UCZENIA SIECI NEURONOWEJ (ostatnie 10):")
            recent_losses = self.dsnn.loss_history[-10:]
            min_loss, max_loss = min(recent_losses), max(recent_losses)

            for i, loss in enumerate(recent_losses):
                if max_loss > min_loss:
                    normalized = (loss - min_loss) / (max_loss - min_loss)
                else:
                    normalized = 0.5
                bar_length = int((1 - normalized) * 20)  # Odwr√≥cone - ni≈ºszy loss = d≈Çu≈ºszy pasek
                bar = "‚ñà" * bar_length + "‚ñë" * (20 - bar_length)
                print(f"  Epoka {i+1:2d}: |{bar}| Loss: {loss:.4f}")

        # Por√≥wnanie wydajno≈õci system√≥w
        if self.session_stats['neural_predictions'] > 0 and total_predictions > 0:
            neural_ratio = self.session_stats['neural_predictions'] / total_predictions * 100
            drm_ratio = 100 - neural_ratio

            print(f"\n‚öñÔ∏è PODZIA≈Å PREDYKCJI:")
            print(f"  DRM: {drm_ratio:.1f}% | Neural: {neural_ratio:.1f}%")

            if self.hybrid_mode:
                print(f"  Hybrydowe: {self.session_stats['hybrid_predictions']}")
                print(f"  Adaptacyjne wagi: Neural={self.neural_weight:.2f}, DRM={self.drm_weight:.2f}")

    def _draw_ascii_chart(self, values):
        """Rysuje prosty wykres ASCII"""
        if not values:
            return
        
        max_val = max(values)
        scale = 50 / max(max_val, 1)  # Skaluj do 50 znak√≥w
        
        for i, val in enumerate(values, 1):
            bar_length = int(val * scale)
            bar = "‚ñà" * bar_length + "‚ñë" * (50 - bar_length)
            print(f"  #{i} |{bar}| {val:.2f}")

    def _draw_progress_bar(self, percentage, label):
        """Rysuje pasek postƒôpu"""
        filled = int(percentage / 2)  # Skaluj do 50 znak√≥w
        bar = "‚ñà" * filled + "‚ñë" * (50 - filled)
        print(f"  {label}: |{bar}| {percentage:.1f}%")
    
    def neural_network_menu(self):
        """Menu zarzƒÖdzania sieciƒÖ neuronowƒÖ"""
        while True:
            print("\n" + "‚îÄ"*50)
            print("üß† DEEP SEMANTIC NEURAL NETWORK - MENU")
            print("‚îÄ"*50)
            print("[1] Status sieci neuronowej")
            print("[2] Trening sieci na danych")
            print("[3] Test predykcji neuronowej")
            print("[4] Analiza podobie≈Ñstwa semantycznego")
            print("[5] Analiza z≈Ço≈ºono≈õci instrukcji")
            print("[6] Konfiguracja trybu hybrydowego")
            print("[7] Eksport modelu neuronowego")
            print("[8] Reset sieci neuronowej")
            print("[q] Wr√≥ƒá do menu g≈Ç√≥wnego")

            choice = input("\nWybierz opcjƒô: ").lower().strip()

            if choice == '1':
                self.show_neural_status()
            elif choice == '2':
                self.train_neural_network()
            elif choice == '3':
                self.test_neural_prediction()
            elif choice == '4':
                self.analyze_semantic_similarity()
            elif choice == '5':
                self.analyze_instruction_complexity()
            elif choice == '6':
                self.configure_hybrid_mode()
            elif choice == '7':
                self.export_neural_model()
            elif choice == '8':
                self.reset_neural_network()
            elif choice == 'q':
                break
            else:
                print("‚ùå Nieprawid≈Çowa opcja")

    def show_neural_status(self):
        """Pokazuje status sieci neuronowej"""
        print("\n" + "="*60)
        print("üß† STATUS DEEP SEMANTIC NEURAL NETWORK")
        print("="*60)

        state = self.dsnn.get_network_state()

        print(f"üìä ARCHITEKTURA SIECI:")
        print(f"  Rozmiary warstw: {state['layer_sizes']}")
        print(f"  Ca≈Çkowita liczba parametr√≥w: {state['total_parameters']:,}")
        print(f"  Rozmiar cache embeddings: {state['cache_size']}")

        print(f"\nüìà METRYKI TRENINGU:")
        print(f"  Pr√≥bek treningowych: {state['training_samples']}")
        print(f"  Aktualny loss: {state['current_loss']:.4f}")
        print(f"  Aktualna dok≈Çadno≈õƒá: {state['current_accuracy']:.2%}")

        print(f"\nü§ù TRYB HYBRYDOWY:")
        print(f"  Status: {'‚úÖ W≈ÇƒÖczony' if self.hybrid_mode else '‚ùå Wy≈ÇƒÖczony'}")
        print(f"  Waga sieci neuronowej: {self.neural_weight:.2f}")
        print(f"  Waga DRM: {self.drm_weight:.2f}")

        # Poka≈º ostatnie krzywe uczenia
        if len(self.dsnn.loss_history) > 0:
            print(f"\nüìâ OSTATNIE 10 WARTO≈öCI LOSS:")
            recent_losses = self.dsnn.loss_history[-10:]
            for i, loss in enumerate(recent_losses):
                print(f"  {i+1:2d}. {loss:.4f}")

    def train_neural_network(self):
        """Trenuje sieƒá neuronowƒÖ na zebranych danych"""
        if not self.neural_training_data:
            print("‚ùå Brak danych treningowych dla sieci neuronowej")
            print("üí° Najpierw wytrenuj system na kodzie (opcja 1)")
            return

        print(f"\nüß† TRENING SIECI NEURONOWEJ")
        print(f"Dostƒôpne dane: {len(self.neural_training_data)} pr√≥bek")

        try:
            epochs = int(input("Liczba epok (domy≈õlnie 10): ") or "10")
            batch_size = min(32, len(self.neural_training_data))

            print(f"\nüîÑ Rozpoczynam trening ({epochs} epok, batch size: {batch_size})")

            # Przygotuj dane
            instructions = [item['instruction'] for item in self.neural_training_data]
            targets = [item['target'] for item in self.neural_training_data]

            # Trening w batch'ach
            for epoch in range(epochs):
                # Shuffle data
                indices = np.random.permutation(len(instructions))

                epoch_loss = 0
                batches = 0

                for i in range(0, len(instructions), batch_size):
                    batch_indices = indices[i:i+batch_size]
                    batch_instructions = [instructions[j] for j in batch_indices]
                    batch_targets = [targets[j] for j in batch_indices]

                    # Trening batch'a
                    self.dsnn.train_batch(batch_instructions, batch_targets, epochs=1)

                    if self.dsnn.loss_history:
                        epoch_loss += self.dsnn.loss_history[-1]
                        batches += 1

                avg_loss = epoch_loss / max(batches, 1)
                print(f"  Epoka {epoch+1}/{epochs}: Loss = {avg_loss:.4f}")

            print("‚úÖ Trening zako≈Ñczony!")

            # Aktualizuj krzywe uczenia
            if self.dsnn.loss_history:
                self.learning_curves['neural_loss'].extend(self.dsnn.loss_history[-epochs:])
            if self.dsnn.accuracy_history:
                self.learning_curves['neural_accuracy'].extend(self.dsnn.accuracy_history[-epochs:])

        except ValueError:
            print("‚ùå B≈Çƒôdna liczba epok")
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas treningu: {e}")

    def test_neural_prediction(self):
        """Testuje predykcjƒô sieci neuronowej"""
        print("\nüß† TEST PREDYKCJI NEURONOWEJ")
        instruction = input("Wprowad≈∫ instrukcjƒô do analizy: ").strip()

        if not instruction:
            return

        try:
            # Analiza przez parser
            instr_type, semantic = self.parser.parse_instruction(instruction)

            # Predykcja neuronowa
            neural_output = self.dsnn.predict(instruction, instr_type)
            neural_prediction = self._interpret_neural_output(neural_output)
            confidence = float(np.max(neural_output))

            # Analiza z≈Ço≈ºono≈õci
            complexity = self.dsnn.analyze_instruction_complexity(instruction, instr_type)

            print(f"\nüìä WYNIKI ANALIZY:")
            print(f"  Instrukcja: {instruction}")
            print(f"  Parser: {instr_type} ‚Üí {semantic}")
            print(f"  Neural: {neural_prediction} (confidence: {confidence:.2f})")

            print(f"\nüîç ANALIZA Z≈ÅO≈ªONO≈öCI:")
            for key, value in complexity.items():
                print(f"  {key.replace('_', ' ').title()}: {value:.3f}")

            # Poka≈º top 5 neuron√≥w wyj≈õciowych
            print(f"\nüß† TOP 5 AKTYWACJI WYJ≈öCIOWYCH:")
            top_indices = np.argsort(neural_output)[-5:][::-1]
            output_labels = ['transfer_data', 'arithmetic_add', 'arithmetic_sub', 'arithmetic_mul',
                           'arithmetic_div', 'compare_values', 'unconditional_jump', 'jump_if_equal']

            for i, idx in enumerate(top_indices):
                if idx < len(output_labels):
                    label = output_labels[idx]
                else:
                    label = f"output_{idx}"
                print(f"  {i+1}. {label}: {neural_output[idx]:.3f}")

        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas predykcji: {e}")

    def analyze_semantic_similarity(self):
        """Analizuje podobie≈Ñstwo semantyczne miƒôdzy instrukcjami"""
        print("\nüîç ANALIZA PODOBIE≈ÉSTWA SEMANTYCZNEGO")

        instr1 = input("Pierwsza instrukcja: ").strip()
        instr2 = input("Druga instrukcja: ").strip()

        if not instr1 or not instr2:
            return

        try:
            # Parsuj instrukcje
            type1, sem1 = self.parser.parse_instruction(instr1)
            type2, sem2 = self.parser.parse_instruction(instr2)

            # Oblicz podobie≈Ñstwo
            similarity = self.dsnn.get_semantic_similarity(instr1, instr2, type1, type2)

            print(f"\nüìä WYNIKI ANALIZY:")
            print(f"  Instrukcja 1: {instr1} ‚Üí {type1}")
            print(f"  Instrukcja 2: {instr2} ‚Üí {type2}")
            print(f"  Podobie≈Ñstwo semantyczne: {similarity:.3f}")

            if similarity > 0.8:
                print("  üü¢ Bardzo wysokie podobie≈Ñstwo")
            elif similarity > 0.6:
                print("  üü° Wysokie podobie≈Ñstwo")
            elif similarity > 0.4:
                print("  üü† ≈örednie podobie≈Ñstwo")
            else:
                print("  üî¥ Niskie podobie≈Ñstwo")

        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas analizy: {e}")

    def analyze_instruction_complexity(self):
        """Analizuje z≈Ço≈ºono≈õƒá instrukcji"""
        print("\nüîç ANALIZA Z≈ÅO≈ªONO≈öCI INSTRUKCJI")
        instruction = input("Wprowad≈∫ instrukcjƒô: ").strip()

        if not instruction:
            return

        try:
            instr_type, semantic = self.parser.parse_instruction(instruction)
            complexity = self.dsnn.analyze_instruction_complexity(instruction, instr_type)

            print(f"\nüìä ANALIZA Z≈ÅO≈ªONO≈öCI: {instruction}")
            print(f"  Typ: {instr_type}")
            print(f"  Semantyka: {semantic}")
            print(f"\nüîç METRYKI Z≈ÅO≈ªONO≈öCI:")

            for key, value in complexity.items():
                if 'complexity' in key:
                    bar_length = int(value * 20)
                    bar = "‚ñà" * bar_length + "‚ñë" * (20 - bar_length)
                    print(f"  {key.replace('_', ' ').title():20s}: |{bar}| {value:.3f}")
                else:
                    print(f"  {key.replace('_', ' ').title():20s}: {value:.3f}")

        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas analizy: {e}")

    def configure_hybrid_mode(self):
        """Konfiguruje tryb hybrydowy"""
        print("\n‚öôÔ∏è KONFIGURACJA TRYBU HYBRYDOWEGO")
        print(f"Aktualny status: {'‚úÖ W≈ÇƒÖczony' if self.hybrid_mode else '‚ùå Wy≈ÇƒÖczony'}")
        print(f"Waga sieci neuronowej: {self.neural_weight:.2f}")
        print(f"Waga DRM: {self.drm_weight:.2f}")

        print("\n[1] W≈ÇƒÖcz/wy≈ÇƒÖcz tryb hybrydowy")
        print("[2] Ustaw wagi rƒôcznie")
        print("[3] Reset do warto≈õci domy≈õlnych")
        print("[4] Tryb adaptacyjny (auto-tuning)")

        choice = input("Wybierz opcjƒô [1-4]: ").strip()

        if choice == '1':
            self.hybrid_mode = not self.hybrid_mode
            status = "w≈ÇƒÖczony" if self.hybrid_mode else "wy≈ÇƒÖczony"
            print(f"‚úÖ Tryb hybrydowy {status}")

        elif choice == '2':
            try:
                neural_w = float(input(f"Waga sieci neuronowej (0.0-1.0, aktualnie {self.neural_weight:.2f}): "))
                if 0.0 <= neural_w <= 1.0:
                    self.neural_weight = neural_w
                    self.drm_weight = 1.0 - neural_w
                    print(f"‚úÖ Ustawiono wagi: Neural={self.neural_weight:.2f}, DRM={self.drm_weight:.2f}")
                else:
                    print("‚ùå Waga musi byƒá miƒôdzy 0.0 a 1.0")
            except ValueError:
                print("‚ùå B≈Çƒôdna warto≈õƒá")

        elif choice == '3':
            self.neural_weight = 0.3
            self.drm_weight = 0.7
            self.hybrid_mode = True
            print("‚úÖ Reset do warto≈õci domy≈õlnych")

        elif choice == '4':
            print("ü§ñ Tryb adaptacyjny w≈ÇƒÖczony - wagi bƒôdƒÖ automatycznie dostrajane")
            self.hybrid_mode = True

    def export_neural_model(self):
        """Eksportuje model sieci neuronowej"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # Eksport wag i bias√≥w
            model_data = {
                'weights': [w.tolist() for w in self.dsnn.weights],
                'biases': [b.tolist() for b in self.dsnn.biases],
                'architecture': {
                    'input_size': self.dsnn.input_size,
                    'hidden_sizes': self.dsnn.hidden_sizes,
                    'output_size': self.dsnn.output_size
                },
                'training_history': {
                    'loss_history': self.dsnn.loss_history,
                    'accuracy_history': self.dsnn.accuracy_history
                },
                'hyperparameters': {
                    'learning_rate': self.dsnn.learning_rate,
                    'momentum': self.dsnn.momentum
                },
                'export_timestamp': timestamp
            }

            filename = f"logos_neural_model_{timestamp}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(model_data, f, ensure_ascii=False, indent=2)

            print(f"‚úÖ Model wyeksportowany: {filename}")
            print(f"üìä Parametry: {sum(w.size for w in self.dsnn.weights):,}")
            print(f"üìà Historia: {len(self.dsnn.loss_history)} epok")

        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd podczas eksportu: {e}")

    def reset_neural_network(self):
        """Resetuje sieƒá neuronowƒÖ"""
        confirm = input("‚ö†Ô∏è Czy na pewno chcesz zresetowaƒá sieƒá neuronowƒÖ? (tak/nie): ").lower()

        if confirm in ['tak', 'yes', 'y']:
            self.dsnn = DeepSemanticNeuralNetwork()
            self.neural_training_data = []
            self.learning_curves['neural_loss'] = []
            self.learning_curves['neural_accuracy'] = []
            print("‚úÖ Sieƒá neuronowa zosta≈Ça zresetowana")
        else:
            print("‚ùå Anulowano reset")

    def run(self):
        """G≈Ç√≥wna pƒôtla programu z rozszerzonymi opcjami"""
        print("üß† LOGOS-ASM ‚Äî Terminal ≈öwiadomo≈õci Kodu")
        print("Semantyczny System Uczenia Kodu Maszynowego z DRM + DSNN")
        print("=" * 60)

        while True:
            print("\n[ MENU G≈Å√ìWNE ]")
            print("1. Trening Modelu (ASCII / Binarne / ASM)")
            print("2. Symulacja Procesora")
            print("3. Introspekcja Kodu")
            print("4. Dynamic Rule Matrix (DRM)")
            print("5. üß† Deep Semantic Neural Network")
            print("6. Eksperymenty Semantyczne")
            print("7. üìä Dashboard Treningu")
            print("8. üìà Krzywe Uczenia")
            print("9. üîç Analiza Wzorc√≥w")
            print("10. üéÆ Interaktywny Trening")
            print("11. Zako≈Ñcz i wyeksportuj dane")
            
            choice = input("\nWybierz opcjƒô [1‚Äì11]: ").strip()

            if choice == '1':
                print("\nTRENING MODELU")
                print("Wprowad≈∫ kod (zako≈Ñcz pustƒÖ liniƒÖ):")
                code_lines = []
                while True:
                    line = input()
                    if not line:
                        break
                    code_lines.append(line)
                
                if code_lines:
                    code = '\n'.join(code_lines)
                    
                    print("\nWybierz typ kodu:")
                    print("[1] Assembler")
                    print("[2] Kod binarny")
                    print("[3] ASCII/Tekst")
                    
                    code_type = input("Typ [1-3]: ").strip()
                    type_map = {'1': 'asm', '2': 'binary', '3': 'ascii'}
                    selected_type = type_map.get(code_type, 'asm')
                    
                    print(f"\nüîÑ Trenowanie na kodzie typu: {selected_type}")
                    self.train_on_code(code, selected_type)
                    
                    print(f"‚úÖ Przetworzono {len(code_lines)} linii kodu")
                    print(f"üìä Statystyki sesji:")
                    for key, value in self.session_stats.items():
                        print(f"  {key}: {value}")
            
            elif choice == '2':
                print("\nSYMULACJA PROCESORA")
                print("Wprowad≈∫ kod assemblera (zako≈Ñcz pustƒÖ liniƒÖ):")
                code_lines = []
                while True:
                    line = input()
                    if not line:
                        break
                    code_lines.append(line)
                
                if code_lines:
                    code = '\n'.join(code_lines)
                    execution_log = self.simulate_processor(code)
                    
                    print(f"\nüìù LOG WYKONANIA ({len(execution_log)} krok√≥w):")
                    for log_entry in execution_log[-10:]:  # Ostatnie 10 wpis√≥w
                        print(f"  {log_entry}")
            
            elif choice == '3':
                print("\nINTROSPEKCJA KODU")
                print("Wprowad≈∫ kod do analizy (zako≈Ñcz pustƒÖ liniƒÖ):")
                code_lines = []
                while True:
                    line = input()
                    if not line:
                        break
                    code_lines.append(line)
                
                if code_lines:
                    code = '\n'.join(code_lines)
                    analysis = self.introspect_code(code)
                    
                    # Dodatkowa analiza ≈õwiadomo≈õci
                    print(f"\nüß† ANALIZA ≈öWIADOMO≈öCI KODU:")
                    semantic_patterns = {}
                    for entry in analysis:
                        sem_type = entry['type']
                        if sem_type in semantic_patterns:
                            semantic_patterns[sem_type] += 1
                        else:
                            semantic_patterns[sem_type] = 1
                    
                    print(f"Wykryte wzorce semantyczne:")
                    for pattern, count in semantic_patterns.items():
                        print(f"  {pattern}: {count} wystƒÖpie≈Ñ")
                    
                    # Predykcja nastƒôpnej instrukcji
                    if analysis:
                        last_type = analysis[-1]['type']
                        print(f"\nüîÆ PREDYKCJA: Na podstawie '{last_type}' przewidujƒô:")
                        self._predict_next_instruction(last_type)
            
            elif choice == '4':
                self.drm_menu()

            elif choice == '5':
                self.neural_network_menu()

            elif choice == '6':
                self.semantic_experiments()

            elif choice == '7':
                self.show_training_dashboard()

            elif choice == '8':
                self.show_learning_curves()

            elif choice == '9':
                self.analyze_learning_patterns()

            elif choice == '10':
                self.interactive_training_mode()

            elif choice == '11':
                print("\nüíæ EKSPORT DANYCH TRENINGOWYCH...")
                self.export_training_data()
                print("\nüëã Dziƒôkujƒô za u≈ºycie LOGOS-ASM!")
                print("System zako≈Ñczy≈Ç pracƒô z pe≈ÇnƒÖ ≈õwiadomo≈õciƒÖ kodu.")
                break

            else:
                print("‚ùå Nieprawid≈Çowa opcja. Wybierz 1-11.")
    
    def _predict_next_instruction(self, last_type: str):
        """Predykcja nastƒôpnej instrukcji na podstawie wzorc√≥w"""
        predictions = {
            'transfer_data': ['arithmetic_add', 'compare_values', 'memory_store'],
            'arithmetic_add': ['compare_values', 'transfer_data', 'memory_store'],
            'compare_values': ['jump_if_equal', 'jump_if_not_equal', 'unconditional_jump'],
            'function_call': ['transfer_data', 'arithmetic_add', 'function_return'],
            'stack_push': ['stack_push', 'function_call', 'stack_pop'],
            'memory_load': ['transfer_data', 'arithmetic_add', 'compare_values']
        }
        
        possible = predictions.get(last_type, ['transfer_data'])
        
        # Znajd≈∫ najsilniejsze regu≈Çy dla predykcji
        best_predictions = []
        for pred_type in possible:
            for rule in self.drm.rules.values():
                if pred_type in rule.pattern.lower():
                    strength = rule.calculate_strength(self.drm.current_time)
                    best_predictions.append((pred_type, strength, rule.semantic))
        
        best_predictions.sort(key=lambda x: x[1], reverse=True)
        
        for i, (pred_type, strength, semantic) in enumerate(best_predictions[:3], 1):
            print(f"  {i}. {pred_type} (si≈Ça: {strength:.2f}) - {semantic}")

    def log_training_metrics(self):
        """Loguje metryki treningu"""
        timestamp = self.drm.current_time
        
        # Oblicz metryki
        total_rules = len(self.drm.rules)
        avg_strength = sum(rule.calculate_strength(timestamp) 
                          for rule in self.drm.rules.values()) / max(total_rules, 1)
        
        total_predictions = (self.session_stats['successful_predictions'] + 
                            self.session_stats['failed_predictions'])
        accuracy = (self.session_stats['successful_predictions'] / max(total_predictions, 1)) * 100
        
        # Zapisz metryki
        metrics = {
            'timestamp': timestamp,
            'total_rules': total_rules,
            'avg_strength': avg_strength,
            'accuracy': accuracy,
            'instructions_processed': self.session_stats['instructions_processed']
        }
        
        self.metrics_log.append(metrics)
        self.learning_curves['accuracy'].append(accuracy)
        self.learning_curves['rule_strength'].append(avg_strength)

    def show_learning_curves(self):
        """Pokazuje krzywe uczenia"""
        print("\n" + "="*80)
        print("üìà KRZYWE UCZENIA")
        print("="*80)
        
        if len(self.learning_curves['accuracy']) < 2:
            print("‚ùå Za ma≈Ço danych do wy≈õwietlenia krzywych")
            return
        
        # Wykres dok≈Çadno≈õci
        print("\nüéØ DOK≈ÅADNO≈öƒÜ W CZASIE:")
        self._plot_ascii_line(self.learning_curves['accuracy'], "Accuracy %")
        
        # Wykres si≈Çy regu≈Ç
        print("\nüí™ ≈öREDNIA SI≈ÅA REGU≈Å:")
        self._plot_ascii_line(self.learning_curves['rule_strength'], "Strength")
        
        # Trend analysis
        recent_accuracy = self.learning_curves['accuracy'][-5:]
        if len(recent_accuracy) >= 2:
            trend = "üìà RosnƒÖcy" if recent_accuracy[-1] > recent_accuracy[0] else "üìâ MalejƒÖcy"
            print(f"\nüîç TREND (ostatnie 5 pomiar√≥w): {trend}")

    def _plot_ascii_line(self, data, label):
        """Rysuje wykres liniowy ASCII"""
        if len(data) < 2:
            return
        
        # Normalizuj dane do 0-20 (wysoko≈õƒá wykresu)
        min_val, max_val = min(data), max(data)
        if max_val == min_val:
            normalized = [10] * len(data)
        else:
            normalized = [int((val - min_val) / (max_val - min_val) * 20) for val in data]
        
        # Rysuj wykres
        for row in range(20, -1, -1):
            line = f"{row:2d} |"
            for val in normalized:
                if val >= row:
                    line += "‚ñà"
                else:
                    line += " "
            if row == 20:
                line += f" Max: {max_val:.2f}"
            elif row == 0:
                line += f" Min: {min_val:.2f}"
            print(line)
        
        # O≈õ X
        x_axis = "   +" + "‚îÄ" * len(data)
        print(x_axis)
        print(f"   {label} over time")

    def analyze_learning_patterns(self):
        """Analizuje wzorce uczenia siƒô systemu"""
        print("\n" + "="*80)
        print("üîç ANALIZA WZORC√ìW UCZENIA")
        print("="*80)
        
        # Analiza regu≈Ç wed≈Çug kategorii
        categories = {}
        for rule in self.drm.rules.values():
            category = self._categorize_rule(rule.pattern)
            if category not in categories:
                categories[category] = []
            categories[category].append(rule)
        
        print("\nüìä REGU≈ÅY WED≈ÅUG KATEGORII:")
        for category, rules in categories.items():
            avg_strength = sum(rule.calculate_strength(self.drm.current_time) 
                              for rule in rules) / len(rules)
            print(f"  {category}: {len(rules)} regu≈Ç, ≈õrednia si≈Ça: {avg_strength:.2f}")
        
        # Analiza ewolucji regu≈Ç
        print("\nüß¨ EWOLUCJA NAJSILNIEJSZYCH REGU≈Å:")
        strongest = self.drm.get_strongest_rules(3)
        for rule in strongest:
            print(f"\nRegu≈Ça #{rule.id}: {rule.pattern}")
            print(f"  Utworzona: iteracja {rule.time_created}")
            print(f"  Wiek: {self.drm.current_time - rule.time_created} iteracji")
            print(f"  Wzrost si≈Çy: {self._calculate_strength_growth(rule):.2f}/iteracja")
            print(f"  Efektywno≈õƒá: {rule.success_rate:.2f}")

    def _categorize_rule(self, pattern):
        """Kategoryzuje regu≈Çƒô wed≈Çug wzorca"""
        pattern_lower = pattern.lower()
        if any(x in pattern_lower for x in ['mov', 'load', 'store']):
            return "Transfer danych"
        elif any(x in pattern_lower for x in ['add', 'sub', 'mul', 'div']):
            return "Arytmetyka"
        elif any(x in pattern_lower for x in ['cmp', 'test']):
            return "Por√≥wnania"
        elif any(x in pattern_lower for x in ['jmp', 'je', 'jne', 'call']):
            return "Kontrola przep≈Çywu"
        elif any(x in pattern_lower for x in ['push', 'pop']):
            return "Stos"
        else:
            return "Inne"

    def _calculate_strength_growth(self, rule):
        """Oblicza wzrost si≈Çy regu≈Çy na iteracjƒô"""
        age = max(self.drm.current_time - rule.time_created, 1)
        current_strength = rule.calculate_strength(self.drm.current_time)
        return current_strength / age

    def interactive_training_mode(self):
        """Interaktywny tryb treningu z live feedback"""
        print("\n" + "="*80)
        print("üéÆ INTERAKTYWNY TRYB TRENINGU")
        print("="*80)
        print("Wprowadzaj kod linia po linii. Wpisz 'help' dla pomocy, 'quit' aby wyj≈õƒá.")
        
        while True:
            print(f"\n[Iteracja {self.drm.current_time}] Wprowad≈∫ instrukcjƒô:")
            instruction = input(">>> ").strip()
            
            if instruction.lower() == 'quit':
                break
            elif instruction.lower() == 'help':
                self._show_training_help()
                continue
            elif instruction.lower() == 'stats':
                self.show_training_dashboard()
                continue
            elif instruction.lower() == 'predict':
                self._interactive_prediction()
                continue
            elif not instruction:
                continue
            
            # Przetw√≥rz instrukcjƒô
            print(f"\nüîÑ Przetwarzanie: {instruction}")
            
            # Poka≈º predykcjƒô przed przetworzeniem
            predicted_type = self._predict_instruction_type(instruction)
            print(f"üîÆ Predykcja: {predicted_type}")
            
            # Przetw√≥rz
            old_stats = self.session_stats.copy()
            self._process_instruction(instruction)
            
            # Poka≈º rezultat
            instr_type, semantic = self.parser.parse_instruction(instruction)
            correct = predicted_type == instr_type
            
            print(f"‚úÖ Rzeczywisty typ: {instr_type}")
            print(f"üìù Semantyka: {semantic}")
            print(f"üéØ Predykcja {'‚úì POPRAWNA' if correct else '‚úó B≈ÅƒòDNA'}")
            
            # Poka≈º zmiany w regu≈Çach
            self._show_rule_changes(instruction, instr_type)
            
            # Aktualizuj metryki
            self.log_training_metrics()
            self.drm.tick()

    def _predict_instruction_type(self, instruction):
        """Przewiduje typ instrukcji przed przetworzeniem"""
        # Znajd≈∫ najbardziej pasujƒÖcƒÖ regu≈Çƒô
        best_match = None
        best_strength = 0
        
        for rule in self.drm.rules.values():
            if rule.pattern.upper() in instruction.upper():
                strength = rule.calculate_strength(self.drm.current_time)
                if strength > best_strength:
                    best_strength = strength
                    best_match = rule
        
        return best_match.pattern if best_match else "UNKNOWN"

    def _show_rule_changes(self, instruction, instr_type):
        """Pokazuje zmiany w regu≈Çach po przetworzeniu"""
        print(f"\nüìä ZMIANY W REGU≈ÅACH:")
        
        # Znajd≈∫ regu≈Çƒô kt√≥ra zosta≈Ça zaktualizowana
        for rule in self.drm.rules.values():
            if instr_type and instr_type.upper() in rule.pattern.upper():
                strength = rule.calculate_strength(self.drm.current_time)
                print(f"  Regu≈Ça #{rule.id}: {rule.pattern}")
                print(f"    Si≈Ça: {strength:.2f}")
                print(f"    U≈ºycia: {rule.count}")
                print(f"    Sukces: {rule.success_rate:.2f}")
                break

    def _interactive_prediction(self):
        """Interaktywna predykcja nastƒôpnej instrukcji"""
        print("\nüîÆ PREDYKCJA NASTƒòPNEJ INSTRUKCJI")
        last_instruction = input("Podaj ostatniƒÖ instrukcjƒô: ").strip()
        
        if last_instruction:
            instr_type, _ = self.parser.parse_instruction(last_instruction)
            if instr_type:
                print(f"\nNa podstawie '{instr_type}' przewidujƒô:")
                self._predict_next_instruction(instr_type)
            else:
                print("‚ùå Nie rozpoznano typu instrukcji")

    def debug_rules(self):
        """Debug mode - poka≈º wszystkie regu≈Çy"""
        print("\n" + "="*60)
        print("üîç DEBUG - WSZYSTKIE REGU≈ÅY")
        print("="*60)
        
        if not self.drm.rules:
            print("‚ùå Brak regu≈Ç w systemie!")
            return
        
        for rule_id, rule in self.drm.rules.items():
            strength = rule.calculate_strength(self.drm.current_time)
            print(f"\nRegu≈Ça #{rule_id}:")
            print(f"  Wzorzec: '{rule.pattern}'")
            print(f"  Semantyka: '{rule.semantic}'")
            print(f"  Si≈Ça: {strength:.2f}")
            print(f"  Waga: {rule.weight:.2f}")
            print(f"  U≈ºycia: {rule.count}")
            print(f"  Sukces: {rule.success_rate:.2f}")
            print(f"  Aktywno≈õƒá: {rule.activity:.2f}")

def main():
    """Funkcja g≈Ç√≥wna programu"""
    try:
        import os
        import sys
        import json
        import math
        import re
        from datetime import datetime
        from dataclasses import dataclass, asdict
        from typing import Dict, List, Optional, Tuple
        
        # Sprawd≈∫ czy wszystkie modu≈Çy sƒÖ dostƒôpne
        print("üîß Inicjalizacja LOGOS-ASM...")
        
        # Utw√≥rz instancjƒô systemu
        logos = LogosASM()
        
        # Uruchom g≈Ç√≥wnƒÖ pƒôtlƒô
        logos.run()
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Przerwano przez u≈ºytkownika")
        print("üíæ Zapisywanie stanu systemu...")
        
        # Awaryjny zapis danych
        try:
            logos.export_training_data()
            print("‚úÖ Stan systemu zapisany pomy≈õlnie")
        except:
            print("‚ùå B≈ÇƒÖd podczas zapisu stanu")
        
        print("üëã LOGOS-ASM zako≈Ñczony")
        
    except Exception as e:
        print(f"\nüí• B≈ÅƒÑD KRYTYCZNY: {e}")
        print("üîç Sprawd≈∫ logi systemu i spr√≥buj ponownie")
        sys.exit(1)


if __name__ == "__main__":
    # Banner startowy
    print("=" * 60)
    print("üß† LOGOS-ASM ‚Äî Terminal ≈öwiadomo≈õci Kodu")
    print("Semantyczny System Uczenia Kodu Maszynowego z DRM")
    print("=" * 60)
    print("üìã ASCII | Binarne | Asembler | Dynamic Rule Matrix")
    print("üéØ Cel: Semantyczne zrozumienie kodu maszynowego")
    print("‚ö° Status: Gotowy do nauki i analizy")
    print("=" * 60)
    
    main()
